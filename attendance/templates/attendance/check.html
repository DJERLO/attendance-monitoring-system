{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="{% static 'css/bootstrap.min.css' %}" rel="stylesheet">
    <link href="{% static 'css/attendance.css' %}" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
    
    <title>Check Attendance</title>
</head>

<body>
    <main>
        <div class="container-fluid text-center mt-4">
            <div class="d-flex justify-content-center align-self-center row g-0">
                <div class="col-md-6 mx-2" id="video-container">
                    <canvas id="canvas"></canvas>
                    <video class="align-self-stretch" id="video" autoplay muted></video>
                </div>

                <div class="col-md-6 flex-grow-1 mx-2" id="form-container">
                    <h2>Attendance Record</h2>
                    <div class="form-group">
                        <label for="employeeName">Name:</label>
                        <input type="text" id="employeeName" class="form-control text-center" readonly>
                    </div>
                    <div class="form-group">
                        <label for="employeeID">Employee ID:</label>
                        <input type="text" id="employeeID" class="form-control text-center" readonly>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Toast Container -->
    <div aria-live="polite" aria-atomic="true" style="position: relative; min-height: 200px;">
        <div class="toast-container position-fixed bottom-0 end-0 p-3">
            <!-- Toasts will be dynamically added here -->
        </div>
    </div>

    <script defer src="{% static 'js/bootstrap.bundle.min.js' %}"></script>
    <script defer src="{% static 'js/face-api.min.js' %}"></script>
    <script type="module">
        import tensorflowtfjs from 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/+esm'
    </script>   
    
    <script>
        document.addEventListener('DOMContentLoaded', async () => {
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const context = canvas.getContext('2d');
            const form = document.getElementById('form-container');
            
            let lastDetectionTime = Date.now();
            const detectionInterval = 1000; // 2 seconds between consecutive face captures
            let matches = [];  // Array to hold recognized names

            let employeeName = document.getElementById('employeeName');
            let employeeID = document.getElementById('employeeID');


            function adjustCanvasSize(video, canvas) {
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                video.width = video.videoWidth;
                video.height = video.videoHeight;
            }

            function getCameraStream() {
                const constraints = {
                    video: {
                        width: { ideal: window.innerWidth },
                        height: { ideal: window.innerHeight },
                        facingMode: "user"
                    }
                };

                // Access webcam stream
                navigator.mediaDevices.getUserMedia(constraints)
                .then(stream => {
                    video.srcObject = stream;
                    video.addEventListener('loadedmetadata', () => {
                        adjustCanvasSize(video, canvas);
                    });
                })
                .catch(err => {
                    console.error("Error accessing webcam: " + err);
                    alert("Could not access the camera. Please check camera permissions and try again.");
                });
            }

            async function loadModels() {
                try {
                    const modelPath = '{% static "js/" %}';
                    await faceapi.nets.ssdMobilenetv1.loadFromUri(modelPath);
                    await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);
                    await faceapi.nets.faceLandmark68Net.loadFromUri(modelPath);
                    await faceapi.nets.faceRecognitionNet.loadFromUri(modelPath);
                } catch (error) {
                    console.error("Error loading models:", error);
                }
            }

            async function detectAndCaptureFaces() {
                console.log(matches)
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                context.clearRect(0, 0, canvas.width, canvas.height);
                let faceNames = [];

                // Draw rectangles and names
                detections.forEach((detection, index) => {
                    const box = detection.detection.box;

                    // Determine if the face is recognized or not
                    const name = matches[index] || "Unknown";  // Use matches to label faces
                    faceNames.push(name); // Store names for the detected faces

                    // Change the stroke color based on recognition status
                    if (name === "Unknown" || name === "Face not recognized" || name === "No match found" || name === "Fake" ) {
                        context.strokeStyle = 'red';  // Red for unrecognized faces
                    } else {
                        context.strokeStyle = 'green';  // Green for recognized faces
                    }

                    // Draw the bounding box around the face
                    context.beginPath();
                    context.rect(box.x, box.y, box.width, box.height);
                    context.lineWidth = 5;
                    context.stroke();

                    // Text settings for name label
                    context.font = '20px Arial';
                    // Change the fillStyle color based on recognition status
                    if (name === "Unknown" || name === "Face not recognized" ||  name === "No match found" || name === "Fake") {
                        context.fillStyle = 'red';  // Red for unrecognized faces or fake faces
                    } else {
                        context.fillStyle = 'green';  // Green for recognized faces
                    }
                    context.fillText(name, box.x, box.y > 10 ? box.y - 5 : 10);  // Display the name above the face
                });

                if (detections.length > 0 && (Date.now() - lastDetectionTime > detectionInterval)) {
                    lastDetectionTime = Date.now(); 
                    await captureAndSendImage(faceNames); // Pass face names for further processing
                } else if (detections.length === 0 && (Date.now() - lastDetectionTime > detectionInterval)) {
                    console.log('No faces detected.');
                    employeeName.value = '';
                }

                requestAnimationFrame(detectAndCaptureFaces);
            }

            function showToast(title, message, type) {
                const toastContainer = document.querySelector('.toast-container');

                // Create a new toast element
                const toast = document.createElement('div');
                const timeString = new Date().toLocaleTimeString(); // Get the current time in a readable format
                toast.className = `toast align-items-center text-bg-${type} border-0`;
                toast.role = 'alert';
                toast.ariaLive = 'assertive';
                toast.ariaAtomic = 'true';
                toast.style = 'min-width: 200px;';
                
                toast.innerHTML = `
                    <div class="toast-header text-white bg-primary">
                        <strong class="me-auto">${title}</strong>
                        <small class="text-white">${timeString}</small> <!-- Use the formatted time here -->
                    </div>
                    <div class="toast-body">
                        ${message}
                    </div>
                `;

                // Append toast to the toast container
                toastContainer.appendChild(toast);

                // Initialize Bootstrap toast
                const bsToast = new bootstrap.Toast(toast, { delay: 3000 }); // Auto-hide after 3000 ms
                bsToast.show();

                // Remove the toast element after it has been hidden
                toast.addEventListener('hidden.bs.toast', () => {
                    toast.remove();
                });
            }

            async function captureAndSendImage(faceNames) {
                console.log("Matching...");
                context.drawImage(video, 0, 0, canvas.width, canvas.height);
                const imgData = canvas.toDataURL('image/jpeg');
                
                fetch('/attendance/', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'X-CSRFToken': '{{ csrf_token }}',
                    },
                    body: JSON.stringify({ image: imgData }),
                })
                .then(response => response.json())
                .then(data => {
                    console.log('Server response:', data);
                    
                    // Assuming your server sends back the names of matched faces
                    matches = data.result.map(item => item.name || item.message);

                    // Update the result label with all recognized names
                    
                    // Check for valid matches (excluding "Unknown" and "No match found")
                    const validMatches = matches.filter(name => name !== "Unknown" && name !== "No match found");

                    // Check if a fake face was detected
                    if (matches.includes("Face not recognized")) {
                        matches[0] = null
                        employeeName.value = '';
                        
                        
                    } else if (validMatches.length > 0 && Array.isArray(matches) && matches.every(match => match !== '' && match !== null && match !== undefined)) {
                        
                        employeeName.value = validMatches[0];
                        showToast('Success!', `Welcome, ${employeeName.value}!`, 'success');
                        
                    } else if (matches.includes("No match found")) {
                        matches[0] = null
                        employeeName.value = '';
                        
                       
                    } else{
                        matches[0] = null
                        
                        employeeName.value = '';
                        
                       
                    }
                    
                })
                .catch((error) => {
                    console.error('Error:', error);
                    
                });
            }

            await loadModels();
            getCameraStream();
    
            window.onresize = function() {
                video.pause();
                getCameraStream();
                adjustCanvasSize(video, canvas);
            };
    
            video.addEventListener('loadedmetadata', () => {
                detectAndCaptureFaces();
            });
        });
    </script>    
</body>
</html>
